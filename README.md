# Аппроксимация функции exp(x/2) с использованием многослойного перцептрона (MLP)

Проект демонстрирует использование многослойного перцептрона (MLP), реализованного с помощью Keras, для аппроксимации функции `y = exp(x/2)`. Сгенерированные данные используются для обучения сети, и результаты аппроксимации визуализируются графически.

## Описание

Проект включает в себя следующие этапы:

1.  **Генерация данных:**  генерируются данные для обучения и тестирования функции `y = exp(x/2)` в заданном диапазоне.
2.  **Нормализация данных:** данные нормализуются с использованием Min-Max масштабирования для приведения значений к диапазону [0, 1].
3.  **Создание многослойного перцептрона (MLP):** создается последовательная модель (Sequential), представляющая собой MLP, с несколькими полносвязными (Dense) слоями, использующими функцию активации ReLU.
4.  **Компиляция модели:**  модель компилируется с использованием оптимизатора Adam и функции потерь MSE (среднеквадратическая ошибка).
5.  **Обучение модели:** модель обучается на нормализованных данных.
6.  **Предсказание:**  модель используется для предсказания значений `y` для тестовой выборки.
7.  **Обратная нормализация:**  предсказанные нормализованные значения преобразуются обратно к исходному масштабу.
8.  **Оценка результатов:** вычисляется среднеквадратическая ошибка (MSE) для оценки качества аппроксимации.
9.  **Визуализация результатов:** строится график, отображающий истинные значения функции, предсказанные значения и обучающую выборку.